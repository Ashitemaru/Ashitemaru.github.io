---
title: 2022 年 9 月论文笔记
date: 2022-09-20 20:48:35
category:
    - 【论文笔记】计算机
mathjax: true
---

这个月正式参与进入了实验室和快手的一个合作项目，依然还是需要从论文先开始。

<!-- more -->

# CausalSim - Unbiased Trace-Driven Network Simulation

## Abstract & Introduction

在测评网络协议在线上的实际性能的时候，虽然 RCT 方法是最为标准的，但是由于其极其昂贵，对周边基础设施的要求也很高，所以只有若干大型网络运营方才能支持这种测评方法。基于此，一般的研究所会选择网络模拟器或者 trace-based simulation。但是网络模拟器往往难以模拟出真实网络环境中的复杂情况，并且这类模拟器需要对网络环境的极其详细的掌握。而 trace-based simulation 又常常因为数据质量不高或者有偏导致测评不精确。

【RCT 方法之后看论文】

应用反事实模拟以利用离线历史数据的主要思路为，首先获取在某一个给定网络条件下使用某一个网络协议时的 trajectory，而我们需要训练一个模型来预测在这个网络条件下使用其他网络协议的时候的 trajectory。基于这个模型，我们只需要已知一个协议的性能，就能够得知新协议的性能表现而不需要实际部署该协议。

使用反事实模拟的好处包括：

- 节省部署协议和使用 RCT 方法评测的成本
- 能够在完全一致的网络条件下比较不同协议的差异
- 使用模型进行反事实模拟得到的数据可在社区内交流，帮助无法访问大型网络以测试其协议设计的开发者

当然，反事实模拟的方法是困难的，原因之一是用于采集观测数据的策略可能破坏无偏性，这一点我们后续阐述。

那么本文的核心成果就是：

{% note info no-icon %}
We present CausalSim, a framework for learning **unbiased trace-driven counterfactual simulation models** for network protocols.
{% endnote %}

## Motivation

总体而言，该文章尝试解决的问题依然是，考虑到直接线上测试算法性能较为耗时且代价较大，能否：

- 使用历史数据预测算法的性能
- 服务运营商能否使用历史数据构建一个模拟器使得开发者可以在不接触实际网络环境的条件下评测算法

### The problem of trace-driven network simulation

这一部分假设了一个新算法 FabABR，然后在 Puffer 数据集上收集了类似 BOLA-BASIC、BBA、Fugu 等已知的算法在给定的网络条件下的 buffer occupancy，令 BOLA-BASIC v1 充当新算法 FabABR，之后构建了两个模型来通过其他已知算法的 buffer occupancy 预测 FabABR 的 buffer occupancy，并和 ground truth 比较。

当然，在实际环境中，我们是没有 ground truth 的，因为我们没有新算法通过 RCT 方法评测得到的 buffer occupancy 作为 ground truth。

第一个模型是 ExpertSim。其原理为，在某个网络条件下，如果某个算法在时刻 $t$ 达成的吞吐率为 $\hat c_t$，那么我们假设在该网络条件下，新算法达成的吞吐率也是 $\hat c_t$。这也是该模型的首要假设，即不同算法对码率的决策不影响观测到的网络吞吐率，而这个假设广泛应用于各种模型。

在这个假设下，记时刻 $t$ 时的 buffer size 为 $b_t$，而时刻 $t + 1$ 时的 buffer size 为 $b_{t + 1}$，时刻 $t$ 的视频块时间为 $T$，根据 FabABR 选择的码率该视频块的大小为 $s_t$，那么：

$$
b_{t + 1} = \max\left(0, b_t - \frac{s_t}{\hat c_t}\right) + T
$$

第二个模型为 SLSim。其模型为两层全链接层，每层 128 个 ReLU 激活的神经元。该网络的输入为 $b_t, \hat c_t, s_t$，输出为 $b_{t + 1}$，符号的意义同上。由于我们具有 ground truth，我们就将其作为 supervisor 进行训练，loss 设定为 L2 loss。最后的实验结果为：

<img src="/uploads/paper-2022-09/1.png" height="50%" width="50%" />

这里可以看见两种模型都不及 CausalSim 做出的预测。而这一差距的本质就是这两个模型都默认了不同算法对码率的决策不影响观测到的网络吞吐率，但实际上由于类似于 TCP 慢启动、和其他流量竞争等因素，不同的码率选择实际上会影响实际的吞吐率。而 Puffer 数据集实际上就能证明该假设错误：

<img src="/uploads/paper-2022-09/2.png" height="50%" width="50%" />

可见不同算法影响了吞吐率的分布。这种错误的假设导致了数据的有偏。

### Causal inference to the rescue

如果我们能够获取更深层次的网络情况而非仅仅是表层的吞吐率，我们完全就能修正原先的错误假设，这是因为我们可以将这些底层的网络情况视作独立于 ABR 算法的因素。

但是这些底层网络情况并不出现在数据集中，我们需要通过表层数据推测这些底层情况，而这也就是反事实推理介入的地方。

具体的设计见下述部分。

## Model

### Causal dynamics

我们给出这样的建模，令 $o_t^\star$ 表示时刻 $t$ 的时候系统观测到的表层数据，$u_t$ 表示时刻 $t$ 的时候系统的底层数据，$a_t$ 表示时刻 $t$ 时我们对系统做出的决策，那么系统行为可以建模为：

$$
o_{t + 1}^\star = \mathcal{F}_{\rm evolution}(o_t^\star, u_t, a_t)
$$

在 ABR 问题中，$o_t^\star$ 包括的因素有 buffer size、实际吞吐率、Min RTT、可选视频块大小，而 $u_t$ 包括的因素有瓶颈连接时间、竞争流量的数量、竞争流量的 congestion control。

此外，我们可以将 $o_t^\star$ 拆分为 $o_t$ 和 $m_t$，这里 $m_t$ 是观测数据中受到底层数据所影响的部分，从而我们可以拆分出纯外部数据 $o_t$，而后续我们所称呼的“观测数据”即指代 $o_t$。这一步拆分后，建模可以变为：

$$
\begin{aligned}
m_t &= \mathcal{F}_{\rm mediation}(a_t, u_t) \\
o_{t + 1} &= \mathcal{F}_{\rm system}(o_t, m_t, a_t) \\
o_t^\star &= [o_t, m_t]
\end{aligned}
$$

这里，我们需要说明的是 $m_t$ 是可观测的，而 $u_t$ 是潜在而不可观测的。另外，$m_t$ 受到决策的影响，而 $u_t$ 不受到决策的影响。

在 ABR 问题中，$m_t$ 就是我们实现的吞吐率，其不仅受到潜在网络环境影响，还受到 ABR 码率决策的影响，而这也就是先前两个策略失败的核心原因。此外，根据该建模，在得知吞吐率 $m_t$ 的信息之后，我们完全不需要了解其他信息即可推断出其他可观测的信息 $o_t$。

### Trace-driven simulation is counterfactual estimation

首先统一符号，我们假设数据集一共采用了 $K$ 种不同算法，一共生成了 $N$ 条 trajectory，我们记第 $i$ 个 trajectory 的长度为 $H_i$。

那么我们的训练策略可以描述为，首先对于任何 $i$，我们给出决策序列 $\{\tilde a_t^i\}_{t = 1}^{H_i}$，给定初始观测 $o_1^i$，并且我们确定所有 trajectory 均基于同一个潜在状态序列 $\{u_t^i\}_{t = 1}^{H_i}$，我们的目的是预测出观测序列 $\{\tilde o_t^i\}_{t = 1}^{H_i}$。

此外，我们注意到学习 $\mathcal{F}_{\rm system}$ 是完全监督的，因为所有需要的数据均可以观测。所以最终的困难点在于估计 $\{u_t^i\}_{t = 1}^{H_i}, \{m_t^i\}_{t = 1}^{H_i}$ 以及学习 $\mathcal{F}_{\rm mediation}$。

## CausalSim - Key insights

### Counterfactual estimation as matrix completion

这一步的核心在于将反事实推理等效为矩阵填充问题。我们假设动作空间大小为 $A$，即 $a_t^i \in \{1, 2, \cdots, A\}$，另外记：

$$
U := \sum_{i = 1}^NH_i
$$

那么我们考虑一个 $A \times U$ 的矩阵，其中每一行代表一种决策，每一列代表潜在状态。这里我们将第 $i$ 个 trajectory 的第 $t$ 时刻中所有的 $(i, t)$ 按 $i$ 为主序数排列为长度为 $U$ 的序列，从而每一个 $(i, t)$ 都能对应到 $M$ 中的某一列。

在第 $i$ 个 trajectory 的第 $t$ 时刻，我们观测到 $m_t^i = \mathcal{F}_{\rm mediation}(a_t^i, u_t^i)$，而 $m_t^i$ 就是矩阵 $M$ 中 $a_t^i$ 所对应的行和 $(i, t)$ 所对应的列处的已知元素，该列其余元素均为未知元素。也就是说我们在初始条件下，每一列都会有一个已知元素。

而现有的矩阵填充算法并不能直接应用到本问题上，因为本问题中的 $M$ 元素缺失的 pattern 并不随机并且缺失元素数量过多。但是另外一方面，矩阵 $M$ 显然具有更为优越的结构，因为元素缺失的 pattern 和已知的 ABR 算法决策流程相关，并且 $N$ 个 trajectory 的网络潜在条件是一致的。

### Exploiting the policy invarience of latent factors

我们这里考虑一个简单情况，即 $A = 2, U = 2n$，并且矩阵 $M$ 秩为 $1$。这说明存在 $a \in \mathbb{R}^2, u \in \mathbb{R}^{2n}$ 满足 $M = au^T$。之后我们令 $K = 2$。

考虑到：

$$
\frac{M_{1, j}}{M_{2, j}} = \frac{a_1u_j}{a_2u_j} = \frac{a_1}{a_2}
$$

并且每一列必然有一个已知元素，所以我们只需要估计 $a_1 / a_2$。

另外，基于两个 trajectory 均基于一致的网络潜在条件，所以对于较大的 $n$，每一列的期望应当类似，所以有以下估计（这个估计我感觉比较奇怪，说理也比较不充分）：

$$
\frac{1}{n}\sum_{j = 1}^n u_j \approx \frac{1}{n}\sum_{j = n + 1}^{2n} u_j
$$

之后我们就可以得到下述估计：

$$
\frac{\sum_{j = 1}^n M_{1, j}}{\sum_{j = n + 1}^{2n} M_{2, j}} = \frac{\sum_{j = 1}^n a_1u_j}{\sum_{j = n + 1}^{2n} a_2u_j} \approx \frac{a_1}{a_2}
$$

从而我们得到了我们需要的估计，从而我们就能补充完整整个矩阵。

## CausalSim - Details

最后采用了这样的一个网络结构：

<img src="/uploads/paper-2022-09/3.png" height="50%" width="50%" />

该网络的目标是为了获取不变的潜在条件 $\{u_t^i\}_{t = 1}^{H_i}$，而完成这项任务的网络是 Policy Discriminator，其接受 $\{u_t^i\}_{t = 1}^{H_i}$ 作为输入，输出为其认为该行为决策是由哪一个算法做出的。由于其为一个简单的多分类任务，所以其 loss 就采用简单的交叉熵表示为：

$$
\mathcal{L}_{\rm disc} := \mathbb{E}_D[-\ln \mathbb{P}(\pi \mid \hat u)]
$$

而我们的目标是让 Policy Discriminator 的 loss 尽可能大，从而通过分类器无法区分各类算法保证抽取的潜在不变条件确实和具体的算法无关。

整个网络采用的 loss 为：

$$
\mathcal{L}_{\rm total} := \mathbb{E}_D[\delta(m_t^i - \hat m_t^i)^2 + (o_t^i - \hat o_t^i)^2] - \kappa\mathcal{L}_{\rm disc}
$$

## Evaluation

### A real-world ABR experiment

实验过程比较简单，问题出现在如何评测。因为 Puffer 数据集里每一个 trajectory 仅使用了一种算法跑过，所以实际上是无法对多个新算法进行评测的。所以其采用了评价变量分布的方式进行评测。即，不同的算法在不同的 trajectory 上运行，只要潜在网络因素不变，各类变量的分布应该是类似的。那么基于此，我们只要再做一次模拟，之后指定一个变量，评价两次模拟中该变量分布之间的差距。这里评价分布的差距使用 EMD：

$$
{\rm EMD}(\mathcal{P}, \mathcal{Q}) := \int_{-\infty}^{+\infty} |\mathcal{P}(x) - \mathcal{Q}(x)| {\rm d}x
$$

这里 $\mathcal{P}, \mathcal{Q}$ 都是累积分布函数。

评测结果自然是 CausalSim 很厉害：

<img src="/uploads/paper-2022-09/4.png" height="50%" width="50%" />

### Learning ABR policies with CausalSim

既然现在已经具有了工作良好的模拟器，我们就可以利用该模拟器训练 ABR，具体的过程不阐述，结果如下：

<img src="/uploads/paper-2022-09/5.png" height="70%" width="70%" />

总体而言，CausalSim 显然和真实环境下训练的结果贴近，而其他的模拟器均有很大偏差。并且对于高 RTT 的 Agent，这个差距更大。这个差距的根本原因依然是其他模拟器都是有偏的，在例如慢启动等条件下，容易选择保守的码率。

### Server load balancing

【PASS】

## Final analysis

读这一篇论文目的是为了研究怎么离线评测算法，也就是训练一个合理的环境模拟器出来。但感觉本文的一个核心思想为将网络吞吐率等因素视作和 ABR 决策有关的变量，将其纳入考虑。严格而言就是更新了对环境内部逻辑的建模，使之更为贴近真实环境。而如果不把网络吞吐率纳入考虑，则前一时刻无论做出什么选择，下一时刻环境都会要求算法实现同样的吞吐率，从而导致算法趋近于保守，在高 RTT Agent 上表现出仅选择较低码率。

方法上的话，感觉 Policy Discriminator 没有太见过，是一个训练无关性的好方法。

# Veritas - Answering Causal Queries from Video Streaming Traces